{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20474c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "import os\n",
    "import time\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41657ab5",
   "metadata": {},
   "source": [
    "## Kafka Admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "632f4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the cluster to run admin functions\n",
    "kafka_admin = KafkaAdminClient(\n",
    "    bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eb028fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before deleting - list of topics: ['__consumer_offsets', 'results', 'chunk_data']\n",
      "After deleting  - list of topics: []\n"
     ]
    }
   ],
   "source": [
    "# delete topics for testing purposes\n",
    "topic_names=kafka_admin.list_topics()\n",
    "print(\"Before deleting - list of topics:\", topic_names)\n",
    "\n",
    "kafka_admin.delete_topics(topics=topic_names)\n",
    "print(\"After deleting  - list of topics:\", kafka_admin.list_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "198a07ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of topics: ['results', 'chunk_data']\n"
     ]
    }
   ],
   "source": [
    "# create new topics\n",
    "# raw data topic\n",
    "topic_in = NewTopic(name='chunk_data',\n",
    "                       num_partitions=12, \n",
    "                       replication_factor=1)\n",
    "# FFT average topic\n",
    "topic_out = NewTopic(name='results',\n",
    "                       num_partitions=12, \n",
    "                       replication_factor=1)\n",
    "\n",
    "\n",
    "kafka_admin.create_topics(new_topics=[topic_in,topic_out])\n",
    "print(\"List of topics:\",kafka_admin.list_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e3bda0",
   "metadata": {},
   "source": [
    "## Kafka Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea19b8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. samples: 8388608 \n",
      "N. bins in frequency spectrum: 3072 \n",
      "N. of slice computed: 2731 \n",
      "delta_nu: 651.0416666666666\n"
     ]
    }
   ],
   "source": [
    "# check constants for data structure\n",
    "print(\"N. samples:\", n_samples,\n",
    "      \"\\nN. bins in frequency spectrum:\", n_bins,\n",
    "      \"\\nN. of slice computed:\", n_slice,\n",
    "      \"\\ndelta_nu:\", delta_nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da333869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to obtain a list of all files\n",
    "# inside folder_path with their complete path\n",
    "def get_file_paths(folder_path):\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "folder_path = \"/home/lupi/AndreaFolder/LocalData/\"\n",
    "file_paths = get_file_paths(folder_path)\n",
    "\n",
    "# reads all files inside input array and returns a list of lists\n",
    "# each containing a pair of real and imaginary files \n",
    "def find_partner(arr):\n",
    "    partner_arr = []\n",
    "    i = 0\n",
    "    \n",
    "    arr=[x[-16:] for x in arr]    # arr is a list with the name of the files\n",
    "    \n",
    "    while i < len(arr):\n",
    "        element = arr[i]\n",
    "        if element.startswith('duck_i_'):\n",
    "            partner = 'duck_q_' + element.split('_')[2]\n",
    "            if partner in arr:\n",
    "                partner_arr.append([element, partner])\n",
    "                arr.remove(element)\n",
    "                arr.remove(partner)\n",
    "            else:\n",
    "                i += 1\n",
    "        elif element.startswith('duck_q_'):\n",
    "            partner = 'duck_i_' + element.split('_')[2]\n",
    "            if partner in arr:\n",
    "                partner_arr.append([partner, element])\n",
    "                arr.remove(element)\n",
    "                arr.remove(partner)\n",
    "            else:\n",
    "                i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return partner_arr \n",
    "\n",
    "    \n",
    "def read_binary_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = file.read()\n",
    "    return data\n",
    "\n",
    "def get_number_from_filename(filename):\n",
    "    return int(filename.split('_')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ff391a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read files, unpack them and send them to Kafka\n",
    "def send_chunks(file_paths,dirPath,DAQ_period=5):\n",
    "    \n",
    "    # returns a list of lists each containing a pair of real and imaginary files \n",
    "    partners = sorted(find_partner(file_paths),\n",
    "                      key=lambda x: get_number_from_filename(x[0]))\n",
    "    \n",
    "    startTot = time.time()\n",
    "    wastedTime=0\n",
    "    \n",
    "    for couple in partners: \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # read all data from input files\n",
    "        couple=[dirPath+x for x in couple]\n",
    "        binary_data_real = read_binary_file(couple[0])\n",
    "        binary_data_imm = read_binary_file(couple[1])\n",
    "\n",
    "        real = bytearray(binary_data_real)\n",
    "        imag = bytearray(binary_data_imm)\n",
    "        \n",
    "        file_num=int(couple[0][-9:-4])\n",
    "        \n",
    "        # unpack data\n",
    "        # each message contains a number of slices equal to slices_per_msg\n",
    "        # (except for the last one of each file, which contains the remainder)\n",
    "        \n",
    "        for f in range(n_slice):\n",
    "            \n",
    "            r_bin = real[4*n_bins*f:4*n_bins*(f+1)] # one float every 4 bytes\n",
    "            i_bin = imag[4*n_bins*f:4*n_bins*(f+1)]\n",
    "            msg = r_bin + i_bin\n",
    "        \n",
    "            # key = file + bin number\n",
    "            key = (file_num).to_bytes(2, \"big\") + f.to_bytes(2, \"big\")\n",
    "           \n",
    "            print(Fore.RED +\"Sending file\",file_num,\"\\tslice number:\",f+1,end=\"\\r\")\n",
    "            \n",
    "            # send to Kafka topic\n",
    "            chunk_producer.send(topic = \"chunk_data\",\n",
    "                                key   = key,\n",
    "                                value = msg)\n",
    "        \n",
    "        end_time1 = time.time()\n",
    "        deltat = end_time1 - start_time\n",
    "        print(\"                                                                 \",end=\"\\r\")\n",
    "        print(\"File\", file_num,\"commissioned in\", round(deltat,3), \"s!\")\n",
    "        \n",
    "        chunk_producer.flush()  # Flush the producer after senting the entire file\n",
    "        \n",
    "        end_time2 = time.time()\n",
    "        deltat = end_time2 - start_time\n",
    "        print(\"File\", file_num,\"completed in\", round(deltat,3), \"s!\")\n",
    "        print(\"------------------------------\")\n",
    "        \n",
    "        wastedTime+=(end_time2 - end_time1)\n",
    "        \n",
    "        # sleep to reproduce DAQ acquisition time\n",
    "        if deltat < DAQ_period:\n",
    "            time.sleep(DAQ_period - deltat)\n",
    "               \n",
    "    endTot = time.time()\n",
    "    deltaTot = endTot - startTot\n",
    "    \n",
    "    print(\"                                                                 \")\n",
    "    print(\"                                                                 \")\n",
    "    print(\"------------------------------\")\n",
    "    print(Fore.GREEN+\"Total time\", round(deltaTot,3), \"s!\")\n",
    "    print(Fore.RED +\"Wasted time\", round(wastedTime,3), \"s!\")\n",
    "    print(Fore.BLACK +\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa1fe60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 0 commissioned in 5.538 s!                                  \n",
      "File 0 completed in 17.823 s!\n",
      "------------------------------\n",
      "File 1 commissioned in 5.521 s!                                  \n",
      "File 1 completed in 16.968 s!\n",
      "------------------------------\n",
      "File 2 commissioned in 5.146 s!                                  \n",
      "File 2 completed in 16.612 s!\n",
      "------------------------------\n",
      "File 3 commissioned in 5.047 s!                                  \n",
      "File 3 completed in 16.555 s!\n",
      "------------------------------\n",
      "File 4 commissioned in 4.914 s!                                  \n",
      "File 4 completed in 15.735 s!\n",
      "------------------------------\n",
      "File 5 commissioned in 5.212 s!                                  \n",
      "File 5 completed in 16.957 s!\n",
      "------------------------------\n",
      "File 6 commissioned in 5.085 s!                                  \n",
      "File 6 completed in 16.786 s!\n",
      "------------------------------\n",
      "File 7 commissioned in 5.244 s!                                  \n",
      "File 7 completed in 17.219 s!\n",
      "------------------------------\n",
      "File 8 commissioned in 5.155 s!                                  \n",
      "File 8 completed in 16.781 s!\n",
      "------------------------------\n",
      "File 9 commissioned in 4.948 s!                                  \n",
      "File 9 completed in 16.641 s!\n",
      "------------------------------\n",
      "File 10 commissioned in 5.18 s!                                  \n",
      "File 10 completed in 17.157 s!\n",
      "------------------------------\n",
      "File 11 commissioned in 5.287 s!                                 \n",
      "File 11 completed in 17.022 s!\n",
      "------------------------------\n",
      "File 12 commissioned in 4.968 s!                                 \n",
      "File 12 completed in 16.499 s!\n",
      "------------------------------\n",
      "File 13 commissioned in 4.944 s!                                 \n",
      "File 13 completed in 16.4 s!\n",
      "------------------------------\n",
      "File 14 commissioned in 5.186 s!                                 \n",
      "File 14 completed in 17.109 s!\n",
      "------------------------------\n",
      "File 15 commissioned in 4.966 s!                                 \n",
      "File 15 completed in 16.506 s!\n",
      "------------------------------\n",
      "                                                                 \n",
      "                                                                 \n",
      "------------------------------\n",
      "\u001b[32mTotal time 268.775 s!\n",
      "\u001b[31mWasted time 186.43 s!\n",
      "\u001b[30m------------------------------\n"
     ]
    }
   ],
   "source": [
    "chunk_producer = KafkaProducer(bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS)\n",
    "send_chunks(file_paths,folder_path)\n",
    "chunk_producer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
